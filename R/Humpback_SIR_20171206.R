# R Script for Bayesian Assessment Model of Humpback Whales - uses the equations
# in Zerbini et al. (2011) Code cleaned up and sent to Andre Punt, John Best and
# Grant Adams on 7 Dec 2017

#' HUMPBACK SIR controls the sampling from the priors, the bisection and
#' likelihoods and the output functions
#'
#' @param file.name name of a file to identified the files exported by the
#'   function
#' @param n.resamples number of resamples to compute the marginal posterior
#'   distributions
#' @param priors List of priors, usually generated using \link{make_prior_list}.
#'   Default is the default of \code{make_prior_list}. See details.
#' @param target_year year of the target population estimate for the bisection
#'   method. Default is 2008
#' @param num.haplotypes number of haplotypes to compute minimum viable
#'   population (from Jackson et al., 2006 and IWC, 2007)
#' @param output.Yrs year for outputing the predicted abundance estimates.
#'   Default is 2008, but multiple years can be specified. For example, if
#'   outputs for 2005 and 2008 are needed, output.Yrs = c(2005, 2008)
#' @param abs.abundance R object containing year, estimate of absolute
#'   abundance, and CV (see example)
#' @param rel.abundance R object containing years, estimates of relative
#'   abudnance and CVs (see example)
#' @param rel.abundance.key key to speficy if relative abundance data are used
#'   in the likelihood. Default is TRUE
#' @param count.data R object containing years, estimates of counts and effort.
#'   NOT USED
#' @param count.data.key key to speficy in count data are used. Default is
#'   FALSE. NOT USED
#' @param growth.rate.obs observed growth rate (1st element) and standard error
#'   (2nd element) as in Zerbni et al. (2011). If third element is FALSE, the
#'   growth rate is not included in the likelihood
#' @param growth.rate.Yrs Years for which the growth.rate.obs were computed (as
#'   in Zerbini et al., 2011)
#' @param catch.data R object containing the years and catches (see example)
#' @param control A list of control parameters, usually generated by
#'   \code{sir_control}.
#'
#' @return A \code{list} containing posterior samples and metadata
#'
#' TODO: Add the negative binomial likelihood for the count data, which is not
#' currently used even though it is defined in the main function call.
#'
#' Current default prior specification:
#' \code{
#' make_prior_list(r_max = make_prior(runif, 0, 0.106),
#'                 K = make_prior(use = FALSE),
#'                 N_obs = make_prior(runif, 500, 20000),
#'                 add_CV = make_prior(use = FALSE),
#'                 z = make_prior(2.39),
#'                 q_IA = make_prior(use = FALSE),
#'                 q_count = make_prior(use = FALSE)}
#'
#' @export
#'
#' @examples
#'
#' \dontrun{
#' HUMPBACK.SIR(file.name = "test.N2005",
#'              n.resamples = 100,
#'              priors = make_prior_list(),
#'              Klim = c(1, 500000),
#'              target_year = 2005,
#'              num.haplotypes = 0,
#'              tolerance.for.bisection = 0.0001,
#'              output.Yrs = c(2005, 2006),
#'              abs.abundance = Abs.Abundance.2005,
#'              rel.abundance = Rel.Abundance,
#'              rel.abundance.key = TRUE,
#'              count.data = Count.Data,
#'              count.data.key = FALSE,
#'              growth.rate.obs = c(0.074, 0.033, TRUE),
#'              growth.rate.Yrs = c(1995, 1996, 1997, 1998),
#'              catch.data = Catch.data,
#'              control = sir_control())
HUMPBACK.SIR <- function(file.name = "NULL",
                         n.resamples = 1000,
                         data,
                         priors,
                         liklist,
                         output.Yrs = c(2008),
                         control = sir_control()) {
  begin.time <- Sys.time()

  ################################
  # Assigning variables
  ################################
  ## Use the first year of the projection is set as the first year in the
  ## catch series
  start_year <- head(data$catch$year, 1)
  end_year <- tail(data$catch$year, 1)

  ## start_year <- catch.data$Year[1]
  ## ## The last year of the projection is set as the last year in the catch or
  ## ## abundance series, whichever is most recent
  ## end_year <- max(tail(catch.data$Year, 1),
  ##               max(abs.abundance$Year),
  ##               max(rel.abundance$Year))
  ## Setting the target year for the bisection method
  ## bisection.Yrs <- target_year-start_year + 1
  ## Setting the years to project
  ## projection.Yrs <- end_year-start_year + 1

  ## Start the loop
  i <- 0
  ## Keep track of number of draws
  draw <- 1
  Cumulative.Likelihood <- 0

  #Creating output vectors
  #-------------------------------------
  names <- c("r_max", "K", "sample.N.obs", "add_CV", "Nmin", "YearMin",
             "violate_MVP", paste("N", output.Yrs, sep = ""),
             paste("ROI_IA", unique(rel.abundance$Index), sep = ""),
             paste("q_IA", unique(rel.abundance$Index), sep = ""),
             paste("ROI_Count", unique(count.data$Index), sep = ""),
             paste("q_Count", unique(count.data$Index), sep = ""),
             "NLL.IAs", "NLL.Count", "NLL.N", "NLL.GR", "NLL", "Likelihood",
             "Max_Dep", paste("status", output.Yrs, sep = ""), "draw", "save")


  samples.output <- matrix(0, nrow = 1, ncol = length(names))
  resamples.output <- matrix(0, nrow = 1, ncol = length(names))
  resamples.trajectories <- matrix(NA, nrow = 1, ncol = nrow(data$catch))
  final.trajectory <- matrix(NA, nrow = nrow(data$catch), ncol = 6)
  Year <- seq(start_year, end_year, by = 1)

  if (control$progress_bar) {
    pb <- txtProgressBar(min = 0, max = n.resamples, style = 3)
  }

  #Initiating the SIR loop
  while (i < n.resamples) {
    #Sampling from Priors
    #-------------------------------
    save <- FALSE #variable to indicate whether a specific draw is kept

    sample <- sample_params(priors = priors,
                            data = data,
                            control = control)

    ## param_sample <- list()
    ## #Sampling for r_max
    ## sample.r_max <- 0.2 #setting sample.r_max outside of the bound
    ## ## FIXME Why is this check necessary; just set the bounds using the prior?
    ## while (sample.r_max < priors$r_max$pars[1] | sample.r_max > priors$r_max$pars[2]) {
    ##   ## Prior on r_max, keep if within boundaries
    ##   sample.r_max <- priors$r_max$rfn()
    ## }
    ## param_sample$r_max <- sample.r_max

    ## ## Sampling from the N.obs prior
    ## sample.N.obs <- priors$N_obs$rfn()
    ## param_sample$N_obs <- sample.N.obs

    ## ## Prior on additional CV
    ## if (priors$add_CV$use) {
    ##   sample.add_CV <- priors$add_CV$rfn()
    ## } else {
    ##   sample.add_CV <- 0
    ## }
    ## param_sample$add_CV <- sample.add_CV

    ## ## Sample from prior for `z` (usually constant)
    ## sample.z <- priors$z$rfn()
    ## param_sample$z <- sample.z

    ## ## Sampling from q priors if q.prior is TRUE; priors on q for indices of
    ## ## abundance
    ## if (priors$q_IA$use) {
    ##   q.sample.IA <- replicate(num.IA, priors$q_IA$rfn())
    ## } else {
    ##   ## FIXME: -9999 is probably not a good sentinel value here; NA?
    ##   q.sample.IA <- rep(-9999, length(unique(rel.abundance$Index)))
    ## }
    ## param_sample$q.IA <- q.sample.IA

    ## ##priors on q for count data
    ## if (priors$q_count$use) {
    ##   q.sample.Count <- replicate(num.Count, priors$q_count$rfn())
    ## } else {
    ##   ## FIXME: Sentinel -9999 again
    ##   q.sample.Count <- rep(-9999, length(unique(count.data$Index)))
    ## }
    ## param_sample$q.count <- q.sample.Count

    ## data <- list(catch = catch.data)
    ## names(data$catch) <- c("year", "catch")
    ## sample.K <- find_K(param_sample = param_sample,
    ##                    target_N = sample.N.obs,
    ##                    tspan = c(start_year, priors$N_obs$year),
    ##                    data = data,
    ##                    control = control)
    ## param_sample$K <- sample.K

    ## #Computing the predicted abundances with the samples from the priors
    ## #----------------------------------------
    ## tspan <- c(start_year, end_year)
    ## Pred_N <- project_population(param_sample = param_sample,
    ##                              data = data,
    ##                              tspan = tspan)

    #Computing the predicted ROI for the IAs and Count data, if applicable
    #----------------------------------------
    #For IAs
    ## Don't calculate ROIs inside the SIR function
    ## rel.abundance.key <- FALSE
    ## if (rel.abundance.key) {
    ##   Pred.ROI.IA <- COMPUTING.ROI(data = rel.abundance,
    ##                                Pred_N = Pred_N,
    ##                                start_year = start_year)
    ## } else {
    ##   Pred.ROI.IA <- rep(0, num.IA)
    ## }

    #For Count Data
    ## Don't calculate ROIs inside the SIR function
    ## count.data.key <- FALSE
    ## if (count.data.key) {
    ##   Pred.ROI.Count <- COMPUTING.ROI(data = count.data,
    ##                                   Pred_N = Pred_N,
    ##                                   start_year = start_year)
    ## } else {
    ##   Pred.ROI.Count <- rep(0, num.Count)
    ## }

    #Calculate Analytical Qs if rel.abundance.key is TRUE
    #---------------------------------------------------------
    ## if (rel.abundance.key) {
    ##   if (!priors$q_IA$use) {
    ##     q.sample.IA <- CALC.ANALYTIC.Q(rel.abundance,
    ##                                    Pred_N$Pred_N,
    ##                                    start_year,
    ##                                    sample.add_CV,
    ##                                    num.IA)
    ##   } else {
    ##   q.sample.IA <- q.sample.IA
    ##   }
    ## }

    #browser()

    ## Calculate Analytical Qs if count.data.key is TRUE
    ## (NOT USED YET - AZerbini, Feb 2013)
    ## if (rel.abundance.key) {
    ##   if (!priors$q_count$use) {
    ##     q.sample.Count <- CALC.ANALYTIC.Q(count.data,
    ##                                       Pred_N$Pred_N,
    ##                                       start_year,
    ##                                       sample.add_CV,
    ##                                       num.Count)
    ##   } else {
    ##   q.sample.Count <- q.sample.Count
    ##   }
    ## }

    ## if (control$verbose > 3) {
    ##   message("r_max = ", sample.r_max,
    ##           " N.obs = ", sample.N.obs,
    ##           " K = ", sample.K,
    ##           " Pred_N.target = ", Pred_N$N[Pred_N$year == priors$N_obs$year],
    ##           " q.IAs = ", q.sample.IA,
    ##           " q.Count = ", q.sample.Count)
    ## }

    ## Compute the likelihoods
    lik <- calc_lik(trajectory = sample$pred_N,
                    param_sample = sample$param_sample,
                    liklist = liklist,
                    log = FALSE)
    #--------------------------------
    # (1) relative indices (if rel.abundance.key is TRUE)
    ## if (rel.abundance.key) {
    ##   lnlike.IAs <- LNLIKE.IAs(rel.abundance,
    ##                            Pred_N$Pred_N,
    ##                            start_year,
    ##                            q.sample.IA,
    ##                            sample.add_CV,
    ##                            TRUE)
    ## } else {
    ##   lnlike.IAs <- 0
    ## }
    ## if (control$verbose > 1) {
    ## }

    # (2) count data (if count.data.key is TRUE)
    ## if (count.data.key) {
    ##   lnlike.Count <- LNLIKE.IAs(count.data,
    ##                              Pred_N$Pred_N,
    ##                              start_year,
    ##                              q.sample.Count,
    ##                              sample.add_CV,
    ##                              log=TRUE)
    ## } else {
    ##   lnlike.Count <- 0
    ## }
    ## if (control$verbose > 1) {
    ## }

    # (3) absolute abundance
    ## lnlike.Ns <- LNLIKE.Ns(abs.abundance,
    ##                        Pred_N$Pred_N,
    ##                        start_year,
    ##                       sample.add_CV,
    ##                        log=TRUE)

    ## # (4) growth rate if applicable
    ## if (growth.rate.obs[3]) {
    ##   ## gr_idx <- 
    ##   Pred.GR <- calc_growth_rate(years = growth.rate.Yrs[c(1, 4)],
    ##                               pred_pop = data.frame(Pred_N = Pred_N$Pred_N,
    ##                                                 year = start_year:end_year))
    ##   lnlike.GR <- LNLIKE.GR(Obs.GR=growth.rate.obs[1],
    ##                          Pred.GR=Pred.GR,
    ##                          GR.SD.Obs=growth.rate.obs[2])
    ## } else {
    ##   lnlike.GR <- 0
    ## }

    ## if (control$verbose > 2) {
    ##   message("lnlike.IAs = ", lnlike.IAs,
    ##           " lnlike.Count = ", lnlike.Count,
    ##           " lnlike.Ns = ", lnlike.Ns,
    ##           " lnlike.GR = ", lnlike.GR)
    ## }

    ## ## These use the likelihoods in Zerbini et al. (2011)
    ## LL <- lnlike.IAs[[1]] + lnlike.Count[[1]] + lnlike.Ns[[1]] + lnlike.GR[[1]]
    ## Likelihood <- exp(-LL)
    ## if (control$verbose > 1) {
    ##   message("NLL = ", LL,
    ##           " Likelihood = ", Likelihood)
    ## }

    ## if (Pred_N$Violate_Min_Viable_Pop) {
    ##   Likelihood <- 0
    ##   if (control$verbose > 0) {
    ##     message("MVP violated on draw", draw)
    ##   }
    ## }

    cum_lik <- cum_lik + lik
    ## Cumulative.Likelihood <- Cumulative.Likelihood + Likelihood

    ## if (!Pred_N$Violate_Min_Viable_Pop) {
      ## while (Cumulative.Likelihood > control$threshold) {
    while(cum_lik > control$threshold) {
      if (control$verbose > 0) {
        message("sample = ", i, " draw = ", draw)
      }
      if (control$verbose > 1) {
        message("draw = ", draw,
                " Likelihood = ", Likelihood,
                " Cumulative = ", Cumulative.Likelihood)
      }
      save <- TRUE
      Cumulative.Likelihood <- Cumulative.Likelihood-control$threshold
      resamples.trajectories <- rbind(resamples.trajectories, Pred_N$Pred_N)
      resamples.output <- rbind(resamples.output,
                                c(sample.r_max,
                                  sample.K,
                                  sample.N.obs,
                                  sample.add_CV,
                                  Pred_N$Min_Pop,
                                  Pred_N$Min_Yr,
                                  Pred_N$Violate_Min_Viable_Pop,
                                  c(Pred_N$Pred_N[output.Yrs - start_year + 1]),
                                  Pred.ROI.IA,
                                  q.sample.IA,
                                  Pred.ROI.Count,
                                  q.sample.Count,
                                  lnlike.IAs[[1]],
                                  lnlike.Count[[1]],
                                  lnlike.Ns[[1]],
                                  lnlike.GR[[1]],
                                  LL,
                                  Likelihood,
                                  Pred_N$Min_Pop / sample.K,
                                  c(Pred_N$Pred_N[output.Yrs - start_year + 1] /
                                    sample.K),
                                  draw,
                                  save))
      i <- i+1
      if (control$progress_bar) {
        setTxtProgressBar(pb, i)
      }
    }

    samples.output <- rbind(samples.output,
                            c(sample.r_max,
                              sample.K,
                              sample.N.obs,
                              sample.add_CV,
                              Pred_N$Min_Pop,
                              Pred_N$Min_Yr,
                              Pred_N$Violate_Min_Viable_Pop,
                              c(Pred_N$Pred_N[output.Yrs-start_year+1]),
                              Pred.ROI.IA,
                              q.sample.IA,
                              Pred.ROI.Count,
                              q.sample.Count,
                              lnlike.IAs[[1]],
                              lnlike.Count[[1]],
                              lnlike.Ns[[1]],
                              lnlike.GR[[1]],
                              LL,
                              Likelihood,
                              Pred_N$Min_Pop/sample.K,
                              c(Pred_N$Pred_N[output.Yrs-start_year+1]/sample.K),
                              draw,
                              save))

    draw <- draw+1
  }

  samples.output <- data.frame(samples.output)
  names(samples.output) <- names
  samples.output <- samples.output[-1, ]
  samples.output.summary <- SUMMARY.SIR(x=samples.output, scenario = file.name)
  ## FIXME Use `paste0` here
  write.csv(samples.output,
            paste(file.name, "_", "samples.output.csv", sep=""))

  resamples.output <- data.frame(resamples.output)
  names(resamples.output) <- names
  resamples.output <- resamples.output[-1, ]
  resamples.output.summary <- SUMMARY.SIR(x = resamples.output,
                                          scenario = file.name)
  ## FIXME Use `paste0` here
  write.csv(resamples.output,
            paste(file.name, "_", "resamples.output.csv", sep=""))

  resamples.trajectories <- data.frame(resamples.trajectories)
  names(resamples.trajectories) <- seq(start_year, end_year,  1)
  resamples.trajectories <- resamples.trajectories[-1, ]
  ## FIXME Use `paste0` here
  write.csv(resamples.trajectories,
            paste(file.name, "_", "resample.trajectories.csv",  sep=""))

  ## FIXME Use one quantile call to get all?
  final.trajectory[, 1] <- sapply(resamples.trajectories, mean)
  final.trajectory[, 2] <- sapply(resamples.trajectories, median)
  final.trajectory[, 3] <- sapply(resamples.trajectories, quantile,
                                  probs = c(0.025))
  final.trajectory[, 4] <- sapply(resamples.trajectories, quantile,
                                  probs = c(0.975))
  final.trajectory[, 5] <- sapply(resamples.trajectories, quantile,
                                  probs = c(0.05))
  final.trajectory[, 6] <- sapply(resamples.trajectories, quantile,
                                  probs = c(0.95))
  final.trajectory <- data.frame(final.trajectory)
  names(final.trajectory) <- c("mean", "median",
                               "PI.2.5%", "PI.97.5%",
                               "PI.5%", "PI.95%")
  final.trajectory <- data.frame(Year, final.trajectory)

  resamples.per.samples <- dim(samples.output)[1] / dim(resamples.output)[1]

  end.time <- Sys.time()
  if (control$verbose > 0) {
    message("Time to Compute = ", (end.time-begin.time))
  }

  list(call = call,
       file.name = file.name,
       Date.Time = Sys.time(),
       Time.to.compute.in.minutes = paste((end.time-begin.time) / 60),
       threshold = control$threshold,
       Ratio.Resamples.per.Sample = paste("1 resample",
                                          ":",
                                          resamples.per.samples,
                                          "samples"),
       resamples.output = resamples.output,
       resamples.output.summary = resamples.output.summary$output.table,
       samples.output.summary = samples.output.summary$output.table,
       final.trajectory = final.trajectory,
       inputs = list(draws = draw,
                     n.resamples = n.resamples,
                     prior_r_max = priors$r_max,
                     priors_N.obs = priors$N.obs,
                     ## target_year = target_year,
                     MVP = paste("num.haplotypes = ",
                                 num.haplotypes,
                                 " MVP = ",
                                 4 * num.haplotypes),
                     tolerance = control$K_bisect_tol,
                     output.Years = output.Yrs))
}



#' OUTPUT FUNCTION
#'
#' Function that provides a summary of SIR outputs including: mean, median, 95%
#' credible interval, 90% predicitive interval, max, and sample size.
#'
#' @param x A data.frame of model outputs including: sample.r_max, sample.K,
#'   sample.N.obs, sample.add_CV, Pred_N$Min_Pop, Pred_N$Min_Yr,
#'   Pred_N$Violate_Min_Viable_Pop, c(Pred_N$Pred_N[output.Yrs-start_year+1]), Pred.ROI.IA,
#'   q.sample.IA, Pred.ROI.Count, q.sample.Count, lnlike.IAs[[1]],
#'   lnlike.Count[[1]], lnlike.Ns[[1]], lnlike.GR[[1]], LL, Likelihood,
#'   Pred_N$Min_Pop/sample.K, c(Pred_N$Pred_N[output.Yrs-start_year+1]/sample.K),
#'   draw, save)
#' @param scenario Name of the model run and object as specified by the user.
#'
#' @return Returns a data.frame with summary of SIR outputs
#'
#' @examples
#' x  <-  rnorm(1000, 5, 7)
#' y  <-  rnorm(1000, 6, 9)
#' df <- data.frame(x = x, y = y)
#' SUMMARY.SIR( df , scenario = "example_summary")
SUMMARY.SIR <- function(x, scenario = "USERDEFINED") {
  num.col <- dim(x)[2]
  col.names <- names(x)
  row.names <- c("mean", "median",
                 "2.5%PI", "97.5%PI",
                 "5%PI", "95%PI",
                 "min", "max", "n")

  ## FIXME Only call quantile once?
  output.summary <- matrix(nrow = length(row.names), ncol = num.col)
  output.summary[1, ] <- sapply(x, mean)
  output.summary[2, ] <- sapply(x, median)
  output.summary[3, ] <- sapply(x, quantile, probs=0.025)
  output.summary[4, ] <- sapply(x, quantile, probs=0.975)
  output.summary[5, ] <- sapply(x, quantile, probs=0.05)
  output.summary[6, ] <- sapply(x, quantile, probs=0.95)
  output.summary[7, ] <- sapply(x, min)
  output.summary[8, ] <- sapply(x, max)
  output.summary[9, ] <- sapply(x, length)

  output.table <- data.frame(output.summary)
  names(output.table) <- col.names
  row.names(output.table) <- row.names
  noquote(format(output.table, digits = 3, scientific = FALSE))

  list(scenario=scenario, date=Sys.time(), output.table=output.table)
}

